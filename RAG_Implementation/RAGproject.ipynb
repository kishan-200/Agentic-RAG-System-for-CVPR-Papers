{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cccd75df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CVPR Research Assistant Ready ---\n",
      "Ask a question about the papers, or type 'exit' to quit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\AppData\\Local\\Temp\\ipykernel_39956\\2162203147.py:22: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
      "e:\\ollama_model\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index loaded with 2310 vectors.\n",
      "Connected to local Ollama model: 'cvpr-gemma-3-4b'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohit\\AppData\\Local\\Temp\\ipykernel_39956\\2162203147.py:37: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=model_name, temperature=0.7)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Answer:\n",
      "] Transformer-based sisr models, hat swinir dat continue deliver strong reconstruction results capturing long-range dependencies. many teams utilized pre-trained transformer models fine-tuned hybrid at- tention s>\n",
      "\n",
      "### Metrics:\n",
      "Latency: 33.69 seconds\n",
      "Retrieved Chunks: 5\n",
      "\n",
      "### Sources:\n",
      "Source 1 (from paper: NTIRE 2025 Challenge on Image Super-Resolution ($\\times$4): Methods and Results):\n",
      "> \"teams surpass last years best psnr score db, ten teams obtain results db, highlighting clear improvement reconstruction accuracy. track perception quality. snucv team ranks first highest perceptual score two teams achieve score seven teams exceed in-...\"\n",
      "Source 2 (from paper: End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model):\n",
      "> \"ieee transactions intelligent transportation systems, vol. no. pp. liu, lin, cao, hu, wei, zhang, lin, guo, swin transformer hierarchical vision transformer using shifted windows, proceedings ieeecvf international conference computer vision, pp. minn...\"\n",
      "Source 3 (from paper: D$^2$-World: An Efficient World Model through Decoupled Dynamic Flow):\n",
      "> \"depth estimation multi-view object detection dynamic temporal stereo. arxiv preprint zhiqi li, wenhai wang, hongyang li, enze xie, chong- hao sima, tong lu, qiao, jifeng dai. bevformer learning birds-eye-view representation multi-camera images via sp...\"\n",
      "Source 4 (from paper: NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused Images: Methods and Results):\n",
      "> \"juan benito affiliations cidaut dgl deraindrop title gsastep members guanglu dong dongguanglustu.scu.edu.cn, xin lin, siyuan liu, tianheng zheng, jiayu zhong, shouyi wang, xiangtai li, lanqing guo, chao ren affiliations sichuan university xdu title r...\"\n",
      "Source 5 (from paper: Enhanced Semantic Extraction and Guidance for UGC Image Super Resolution):\n",
      "> \"bilize training process become key research direc- tion. transformer-based sisr transformer architecture, originally designed nat- ural language processing, neural network framework relies entirely self-attention mechanisms capture global dependencie...\"\n",
      "Exiting...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "import os\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "# --- Configuration ---\n",
    "FAISS_INDEX_PATH = \"faiss_cvpr_index\"  \n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "LOCAL_OLLAMA_MODEL = \"cvpr-gemma-3-4b\"\n",
    "TOP_K = 5  # Number of relevant chunks\n",
    "MAX_TOKENS = 512  # Limit response length\n",
    "\n",
    "# --- Load FAISS Vector Store and Retriever ---\n",
    "def load_vector_store(index_path: str) -> FAISS:\n",
    "    \"\"\"Load the FAISS vector store with error handling.\"\"\"\n",
    "    if not os.path.exists(index_path):\n",
    "        raise FileNotFoundError(f\"FAISS index not found at {index_path}. Check the path.\")\n",
    "    try:\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "        vector_store = FAISS.load_local(\n",
    "            index_path,\n",
    "            embeddings=embeddings,\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "        print(f\"FAISS index loaded with {vector_store.index.ntotal} vectors.\")\n",
    "        return vector_store\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load FAISS index: {e}\")\n",
    "\n",
    "# --- Connect to Ollama Model ---\n",
    "def connect_ollama(model_name: str) -> Ollama:\n",
    "    \"\"\"Connect to the local Ollama model with error handling.\"\"\"\n",
    "    try:\n",
    "        llm = Ollama(model=model_name, temperature=0.7)\n",
    "        print(f\"Connected to local Ollama model: '{model_name}'.\")\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to connect to Ollama: {e}. Ensure Ollama is running.\")\n",
    "\n",
    "# --- Define Prompt Template ---\n",
    "prompt_template_str = \"\"\"<s>[INST] You are an assistant for question-answering tasks on CVPR research papers.\n",
    "Use the following pieces of retrieved context to answer the question concisely.\n",
    "If you don't know the answer or the context is insufficient, say 'I donâ€™t know.'\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer: [/INST]\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template_str)\n",
    "\n",
    "# --- RAG Pipeline ---\n",
    "def rag_pipeline(query: str, vector_store: FAISS, llm: Ollama) -> Dict:\n",
    "    \"\"\"Execute the RAG pipeline with retrieval and generation.\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=TOP_K)\n",
    "    context_string = \"\\n\\n---\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    # Format and generate response\n",
    "    formatted_prompt = prompt.format(context=context_string, question=query)\n",
    "    try:\n",
    "        response = llm.invoke(formatted_prompt)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Generation failed: {e}\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    latency = time.time() - start_time\n",
    "    metrics = {\n",
    "        \"latency\": latency,\n",
    "        \"retrieved_count\": len(retrieved_docs),\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"context\": context_string,\n",
    "        \"metrics\": metrics,\n",
    "        \"sources\": retrieved_docs\n",
    "    }\n",
    "\n",
    "# --- Interactive Q&A Loop ---\n",
    "def main():\n",
    "    print(\"\\n--- CVPR Research Assistant Ready ---\")\n",
    "    print(\"Ask a question about the papers, or type 'exit' to quit.\")\n",
    "    \n",
    "    # Initialize components\n",
    "    try:\n",
    "        vector_store = load_vector_store(FAISS_INDEX_PATH)\n",
    "        llm = connect_ollama(LOCAL_OLLAMA_MODEL)\n",
    "    except Exception as e:\n",
    "        print(f\"Initialization failed: {e}\")\n",
    "        return\n",
    "    \n",
    "    while True:\n",
    "        user_query = input(\"\\nYour Question: \").strip()\n",
    "        if user_query.lower() == 'exit':\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            result = rag_pipeline(user_query, vector_store, llm)\n",
    "            print(\"\\n### Answer:\")\n",
    "            print(result[\"response\"])\n",
    "            print(\"\\n### Metrics:\")\n",
    "            print(f\"Latency: {result['metrics']['latency']:.2f} seconds\")\n",
    "            print(f\"Retrieved Chunks: {result['metrics']['retrieved_count']}\")\n",
    "            print(\"\\n### Sources:\")\n",
    "            for i, doc in enumerate(result[\"sources\"]):\n",
    "                print(f\"Source {i+1} (from paper: {doc.metadata.get('title', 'N/A')}):\")\n",
    "                print(f\"> \\\"{doc.page_content[:250]}...\\\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
