{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18f8f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 papers. Ingesting into Neo4j...\n",
      "  (1/50) Ingested 'SLRTP2025 Sign Language Production Challenge: Methodology, Results, and Future Work'\n",
      "  (2/50) Ingested 'HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors'\n",
      "  (3/50) Ingested 'CuriosAI Submission to the EgoExo4D Proficiency Estimation Challenge 2025'\n",
      "  (4/50) Ingested 'ZERO: Industry-ready Vision Foundation Model with Multi-modal Prompts'\n",
      "  (5/50) Ingested 'Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration'\n",
      "  (6/50) Ingested 'DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025'\n",
      "  (7/50) Ingested 'End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model'\n",
      "  (8/50) Ingested 'Exploring Non-contrastive Self-supervised Representation Learning for Image-based Profiling'\n",
      "  (9/50) Ingested 'NTIRE 2025 Challenge on HR Depth from Images of Specular and Transparent Surfaces'\n",
      "  (10/50) Ingested 'GazeNLQ @ Ego4D Natural Language Queries Challenge 2025'\n",
      "  (11/50) Ingested 'Multi-view Surface Reconstruction Using Normal and Reflectance Cues'\n",
      "  (12/50) Ingested 'OSGNet @ Ego4D Episodic Memory Challenge 2025'\n",
      "  (13/50) Ingested 'NTIRE 2025 XGC Quality Assessment Challenge: Methods and Results'\n",
      "  (14/50) Ingested 'Technical Report for Ego4D Long-Term Action Anticipation Challenge 2025'\n",
      "  (15/50) Ingested 'PCIE_Interaction Solution for Ego4D Social Interaction Challenge'\n",
      "  (16/50) Ingested 'HMAD: Advancing E2E Driving with Anchored Offset Proposals and Simulation-Supervised Multi-target Scoring'\n",
      "  (17/50) Ingested 'Boosting Adversarial Transferability via High-Frequency Augmentation and Hierarchical-Gradient Fusion'\n",
      "  (18/50) Ingested 'RefAV: Towards Planning-Centric Scenario Mining'\n",
      "  (19/50) Ingested 'HCQA-1.5 @ Ego4D EgoSchema Challenge 2025'\n",
      "  (20/50) Ingested 'Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models'\n",
      "  (21/50) Ingested 'SuperAD: A Training-free Anomaly Classification and Segmentation Method for CVPR 2025 VAND 3.0 Workshop Challenge Track 1: Adapt & Detect'\n",
      "  (22/50) Ingested 'NTIRE 2025 Challenge on Video Quality Enhancement for Video Conferencing: Datasets, Methods and Results'\n",
      "  (23/50) Ingested 'Four Eyes Are Better Than Two: Harnessing the Collaborative Potential of Large Models via Differentiated Thinking and Complementary Ensembles'\n",
      "  (24/50) Ingested 'NTIRE 2025 challenge on Text to Image Generation Model Quality Assessment'\n",
      "  (25/50) Ingested 'DenseGrounding: Improving Dense Language-Vision Semantics for Ego-Centric 3D Visual Grounding'\n",
      "  (26/50) Ingested 'Event-Based Eye Tracking. 2025 Event-based Vision Workshop'\n",
      "  (27/50) Ingested 'NTIRE 2025 Challenge on Image Super-Resolution ($\\times$4): Methods and Results'\n",
      "  (28/50) Ingested 'NTIRE 2025 Challenge on Day and Night Raindrop Removal for Dual-Focused Images: Methods and Results'\n",
      "  (29/50) Ingested 'Instruction-augmented Multimodal Alignment for Image-Text and Element Matching'\n",
      "  (30/50) Ingested 'PVUW 2025 Challenge Report: Advances in Pixel-level Understanding of Complex Videos in the Wild'\n",
      "  (31/50) Ingested 'MASSeg : 2nd Technical Report for 4th PVUW MOSE Track'\n",
      "  (32/50) Ingested 'Dual-Path Enhancements in Event-Based Eye Tracking: Augmented Robustness and Adaptive Temporal Modeling'\n",
      "  (33/50) Ingested 'Enhanced Semantic Extraction and Guidance for UGC Image Super Resolution'\n",
      "  (34/50) Ingested 'The 1st Solution for 4th PVUW MeViS Challenge: Unleashing the Potential of Large Multimodal Models for Referring Video Segmentation'\n",
      "  (35/50) Ingested 'Exploring Temporal Dynamics in Event-based Eye Tracker'\n",
      "  (36/50) Ingested 'ReferDINO-Plus: 2nd Solution for 4th PVUW MeViS Challenge at CVPR 2025'\n",
      "  (37/50) Ingested 'Technical Report for the 5th CLVision Challenge at CVPR: Addressing the Class-Incremental with Repetition using Unlabeled Data -- 4th Place Solution'\n",
      "  (38/50) Ingested 'Enhancing Facial Expression Recognition through Dual-Direction Attention Mixed Feature Networks and CLIP: Application to 8th ABAW Challenge'\n",
      "  (39/50) Ingested 'Design of an Expression Recognition Solution Based on the Global Channel-Spatial Attention Mechanism and Proportional Criterion Fusion'\n",
      "  (40/50) Ingested 'Feature Fusion Attention Network with CycleGAN for Image Dehazing, De-Snowing and De-Raining'\n",
      "  (41/50) Ingested 'A Comprehensive Survey on Composed Image Retrieval'\n",
      "  (42/50) Ingested 'Survey on Single-Image Reflection Removal using Deep Learning Techniques'\n",
      "  (43/50) Ingested 'EventEgo3D++: 3D Human Motion Capture from a Head-Mounted Event Camera'\n",
      "  (44/50) Ingested 'MaIR: A Locality- and Continuity-Preserving Mamba for Image Restoration'\n",
      "  (45/50) Ingested 'Separating Drone Point Clouds From Complex Backgrounds by Cluster Filter -- Technical Report for CVPR 2024 UG2 Challenge'\n",
      "  (46/50) Ingested 'Unsupervised UAV 3D Trajectories Estimation with Sparse Point Clouds'\n",
      "  (47/50) Ingested 'Efficient Quantization-Aware Training on Segment Anything Model in Medical Images and Its Deployment'\n",
      "  (48/50) Ingested 'Driving with InternVL: Oustanding Champion in the Track on Driving with Language of the Autonomous Grand Challenge at CVPR 2024'\n",
      "  (49/50) Ingested 'Second FRCSyn-onGoing: Winning Solutions and Post-Challenge Analysis to Improve Face Recognition with Synthetic Data'\n",
      "  (50/50) Ingested 'D$^2$-World: An Efficient World Model through Decoupled Dynamic Flow'\n",
      "\n",
      "Ingestion complete.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# --- Configuration ---\n",
    "# 1. Neo4j AuraDB Credentials (Update with your own)\n",
    "NEO4J_URI = \"neo4j://127.0.0.1:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"12345678\"\n",
    "\n",
    "# 2. Path to your data file\n",
    "# Make sure this file is in the same directory as the script,\n",
    "# or provide the full path.\n",
    "JSONL_FILE_PATH = \"processed_data/cvpr_papers_cleaned.jsonl\"\n",
    "\n",
    "# --- Data Loading ---\n",
    "def load_papers_from_jsonl(file_path):\n",
    "    \"\"\"Loads paper data from a .jsonl file.\"\"\"\n",
    "    papers = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            papers.append(json.loads(line))\n",
    "    return papers\n",
    "\n",
    "# --- Neo4j Ingestion Logic ---\n",
    "def get_neo4j_driver():\n",
    "    \"\"\"Connects to the Neo4j database.\"\"\"\n",
    "    return GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "\n",
    "def add_paper_to_graph(tx, paper_data):\n",
    "    \"\"\"Adds a paper, its authors, and keywords to the graph.\"\"\"\n",
    "    \n",
    "    # Extract keywords from the summary (a simple method)\n",
    "    # You could use a more advanced NLP method here if needed.\n",
    "    summary = paper_data.get('summary', '')\n",
    "    keywords = [word for word in summary.split() if len(word) > 5 and word.lower() not in ['challenge', 'paper', 'results', 'method', 'dataset']]\n",
    "    unique_keywords = list(set(keywords[:5])) # Take up to 5 unique keywords\n",
    "\n",
    "    # Use MERGE to avoid creating duplicate nodes\n",
    "    # Create the Paper node\n",
    "    query_paper = \"MERGE (p:Paper {title: $title})\"\n",
    "    tx.run(query_paper, title=paper_data['title'])\n",
    "\n",
    "    # Create Author nodes and AUTHORED relationships\n",
    "    for author_name in paper_data.get('authors', []):\n",
    "        query_author = \"\"\"\n",
    "        MERGE (a:Author {name: $author_name})\n",
    "        WITH a\n",
    "        MATCH (p:Paper {title: $paper_title})\n",
    "        MERGE (a)-[:AUTHORED]->(p)\n",
    "        \"\"\"\n",
    "        tx.run(query_author, author_name=author_name, paper_title=paper_data['title'])\n",
    "\n",
    "    # Create Keyword nodes and MENTIONS relationships\n",
    "    for keyword in unique_keywords:\n",
    "        query_keyword = \"\"\"\n",
    "        MERGE (k:Keyword {term: $keyword})\n",
    "        WITH k\n",
    "        MATCH (p:Paper {title: $paper_title})\n",
    "        MERGE (p)-[:MENTIONS]->(k)\n",
    "        \"\"\"\n",
    "        tx.run(query_keyword, keyword=keyword, paper_title=paper_data['title'])\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    driver = get_neo4j_driver()\n",
    "    papers = load_papers_from_jsonl(JSONL_FILE_PATH)\n",
    "    \n",
    "    print(f\"Found {len(papers)} papers. Ingesting into Neo4j...\")\n",
    "    with driver.session() as session:\n",
    "        for i, paper in enumerate(papers):\n",
    "            if 'title' in paper and 'authors' in paper:\n",
    "                session.execute_write(add_paper_to_graph, paper)\n",
    "                print(f\"  ({i+1}/{len(papers)}) Ingested '{paper['title']}'\")\n",
    "            \n",
    "    print(\"\\nIngestion complete.\")\n",
    "    driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
