{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdYfoM57ys_b"
      },
      "source": [
        "## **Step 1: Installing dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y7hPiclVSRc1",
        "outputId": "ebc53692-cc3c-44c7-bfff-e53381253b18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.47.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6fa46f9d098d49c89b95b9a174975308",
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install torch transformers peft datasets bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "845xz3QISRfp",
        "outputId": "ad82654d-002e-4d63-e3c0-6ed40284b823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting trl\n",
            "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.10.0)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.0.0)\n",
            "Requirement already satisfied: transformers>=4.55.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.55.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.4.0->trl) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.55.0->trl) (0.21.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.8.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.2)\n",
            "Downloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trl\n",
            "Successfully installed trl-0.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install trl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7s-L5pHzdR0"
      },
      "source": [
        "**CUDA MEMORY RESET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEuub_ZASRm7"
      },
      "outputs": [],
      "source": [
        "!pip install numba\n",
        "\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlNv5qMGzGJF"
      },
      "source": [
        "# **Step 2: Logging into hugging face**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-UbHBc_SRiF",
        "outputId": "93eda759-ad8e-4976-eeb9-e6cbd411de93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `kishanmodel` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `kishanmodel`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49KkfQS40Qyl"
      },
      "source": [
        "# **Step 3: Finetuning with QLoRA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNFs6bEiSJ-_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer\n",
        "import os\n",
        "import json\n",
        "\n",
        "# --- Configuration ---\n",
        "model_name = \"google/gemma-3-4b-it\"  # 4B params model\n",
        "dataset_path = \"cvpr_finetuning_formatted.jsonl\"\n",
        "new_model_name = \"gemma-3-4b-cvpr\"  # Adapter output\n",
        "target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
        "\n",
        "# QLoRA config\n",
        "lora_r = 64\n",
        "lora_alpha = 16\n",
        "lora_dropout = 0.1\n",
        "\n",
        "# BitsAndBytes (4-bit)\n",
        "use_4bit = True\n",
        "bnb_4bit_compute_dtype = \"float16\"\n",
        "bnb_4bit_quant_type = \"nf4\"\n",
        "use_nested_quant = False\n",
        "\n",
        "# Training args (for Colab T4 ~16GB VRAM)\n",
        "output_dir = \"./results\"\n",
        "num_train_epochs = 1\n",
        "fp16 = True\n",
        "bf16 = False\n",
        "per_device_train_batch_size = 1\n",
        "gradient_accumulation_steps = 4\n",
        "gradient_checkpointing = True\n",
        "max_grad_norm = 0.3\n",
        "learning_rate = 2e-4\n",
        "weight_decay = 0.001\n",
        "optim = \"paged_adamw_8bit\"\n",
        "lr_scheduler_type = \"cosine\"\n",
        "max_steps = -1\n",
        "warmup_ratio = 0.03\n",
        "group_by_length = True\n",
        "save_steps = 25\n",
        "logging_steps = 5\n",
        "dataset = load_dataset('json', data_files=dataset_path, split=\"train\")\n",
        "\n",
        "# --- Quantization Config ---\n",
        "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=use_4bit,\n",
        "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
        "    bnb_4bit_compute_dtype=compute_dtype,\n",
        "    bnb_4bit_use_double_quant=use_nested_quant,\n",
        ")\n",
        "\n",
        "# --- Load Model ---\n",
        "print(f\"Loading {model_name}...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1\n",
        "\n",
        "# --- Load Tokenizer ---\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "# --- LoRA Config ---\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=lora_alpha,\n",
        "    lora_dropout=lora_dropout,\n",
        "    r=lora_r,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=target_modules\n",
        ")\n",
        "\n",
        "# --- Training Args ---\n",
        "training_arguments = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    per_device_train_batch_size=per_device_train_batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    optim=optim,\n",
        "    save_steps=save_steps,\n",
        "    logging_steps=logging_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    fp16=fp16,\n",
        "    bf16=bf16,\n",
        "    max_grad_norm=max_grad_norm,\n",
        "    max_steps=max_steps,\n",
        "    warmup_ratio=warmup_ratio,\n",
        "    group_by_length=group_by_length,\n",
        "    lr_scheduler_type=lr_scheduler_type,\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "# --- SFTTrainer ---\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    peft_config=peft_config,\n",
        "    args=training_arguments,\n",
        ")\n",
        "\n",
        "# --- Train ---\n",
        "print(\"Starting fine-tuning...\")\n",
        "trainer.train()\n",
        "\n",
        "# --- Save Adapter ---\n",
        "print(f\"Saving adapter to {new_model_name}...\")\n",
        "trainer.model.save_pretrained(new_model_name)\n",
        "\n",
        "print(\"Fine-tuning complete! Adapter saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvMsdNOz1d3b"
      },
      "source": [
        "# **Step 4: Merge the fine tuned parameters with Base Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633,
          "referenced_widgets": [
            "7cb05d151ad8497ea572b8bd3bfa88cb",
            "0574e85d4ba2425b8f1cdd02aea40891",
            "6f04c0dddb1a4723a131f17e31f278ba",
            "dfac8a771d85424da4bca9f327dbc656",
            "d8725c4a0f3c4ee495545eb4f0f69944",
            "ff5b5ce5ed1149ff81de93277bc1b902",
            "9cfaf769a7ff4859b14e64bbb2e64016",
            "00794e9f77c74bedbae4d917e90667e5",
            "130a4b12e6454e8fb24cf4494b7da68e",
            "b5604d12090646df905d25a536d7f2ad",
            "279b09dcc33b4089aba54910b7ddd8a7",
            "f17a7ec2b4c344f791453234faf927a2",
            "08ea2b75483e4bac927555ec0278cd92",
            "028b8c03ee9f4e219ffab1911fd8d5d9",
            "0912a475313f4ae9893673866bb55920",
            "119758192f464254817372255e315ca8",
            "8dad0d502d9e4395a6915ffaedd2bea4",
            "b92440c3d37144d79580ab3e2ed2c760",
            "528a572c56934083936662ee044cd0d3",
            "0fe80ffb3fc34647a3581605fbd07df6",
            "ef81a31613bc417a80f426af81991d83",
            "fec0b860a5114a9b848a4c1c76db2b8b",
            "2a4603ba9f0a4012a19a96b5bd7173ef",
            "0124a88b488940608d490e2ea8c99b19",
            "0f2b28f6a1394430a30ab24238f29af1",
            "ed8ac87f09b4470d814778580d7d0127",
            "b1efd115ab81498c96ee9e98aef96777",
            "15f8687038ec48f0b5b119eced928ced",
            "f6f521772d21415da8ba911b73707819",
            "d0b39f3de8b44f05810159bb8a616147",
            "0b522798f5884631b8ddc5190c11ec47",
            "3ff6f2769e154ea6a51f4afdb752f2a2",
            "e852cd07728d48aabbb3b363704e44bf",
            "5d3d9353b4d543c39d0be7ee2ba32936",
            "dfcab6dc6e7842fcaa03590a0b935d83",
            "d242a9860a274c2fbbed28e382dee554",
            "962c4dfab86742019773ebe19e3b3aae",
            "9e99e578d4b54e7e9bdfb99e7cac6f62",
            "3795615b2cab4189966699aba3f263d2",
            "100776baf73e44faa0c72863b21dbe81",
            "1b61231cd91449ada00d7a11d0e7dfe5",
            "72f0e99faddf4bc5859d0938febcaaa7",
            "5d4389c6344049399dd3f8f683d83403",
            "e31c5edada3b484b907a51077a05d288",
            "6a476002a9e344a083a1686544fd5252",
            "dd87846c577b4f2a9ff66c112b772b12",
            "eef9d3e14c804c86b668f9a4eaff141d",
            "bd0f8e4f2cc0431dac0bee226af41415",
            "db8740ca76e34a85b90c898ccd952ff8",
            "c0bd159a46c441648f1f6fa0bf1fef7d",
            "a3b25709c62942b2bf56e6a726417e0e",
            "215a19cc49054acd9afbfd2a215b6e6a",
            "c9e8ec5a8c11472a99dbd5b679a3a572",
            "f855a6c300ca481a92347176780a720b",
            "1af245da1b394ccba723c8b2cb4c8d36",
            "a246d0a4f28f4e6ea69ec3b2a15c0bef",
            "ba67e4c09df84e809619c790f71546ac",
            "95c7648da0044dd0bba816eb43d813d2",
            "00e115db6d5b417abc38a3b2f86a4c04",
            "0ddcc2dfd6c540e3a49bfc11f5a59e9f",
            "9c73151b544044d9af59e2057cf1e5a0",
            "4004b7635d544e59ba2ffe3297c8e983",
            "f3df2b0087124db6984ec75b52fb03ea",
            "a5bbe08b521d438b9047935cfa6ea71e",
            "85ddfa0895e746ea93f8639c4e14cb99",
            "fc1038d1ad554865996b57172569a661",
            "de273b91d02c4802aef68f8e5bf07fa9",
            "f9f54fb47ff94a3195bec8e0f54b4096",
            "3174e818e510457a821b0563dcd70bce",
            "e9dcf76d8c54434dabf32004a015493f",
            "ef621668e93b4c169af80dd5548723e0",
            "decd3cb8d67c4f75818f1d1a748a62fe",
            "cddec2b417bc4f50b54b6f6960c02d8f",
            "fd900cd1975e4baead05350f82017293",
            "7b14970f68604a8087011a00d3db20c4",
            "74957acb3c60499b9a1a366f6c9c9db6",
            "baa1c14c050740daac3c66a8a870c9b9",
            "10b5e986a13041a382519fb1913e8e65",
            "7c7c324abfce4a15bce105b0eb4137be",
            "d9e52e21643c430a9041f3d2954f1357",
            "6dac6837cbc54cb7bdddd16e2fb7fe4b",
            "1c74c9a02c81407ba254560f21411f5d",
            "62843bdfcca44405a598193402527a00",
            "f7c6eff3034d4e25aafef35ef8c187cf",
            "bec1c667580e4658bca78ce615106488",
            "9df4d7143c8f451a9bb89de45d322ad0",
            "49926dd314b74d4b9e655c5175e405e1",
            "a08623735f7949759c9e870bcc4aa893",
            "1d3ceab287db44328653b1626bc04c2b",
            "1c08b3c90e3d42bd8747fd96ca3d8e1c",
            "8b47b2ddfe8442838a88ce54fab3957b",
            "8d1c1e5a844047c8b1d59d42acd5c66f",
            "905b637c9d714680bf35c53ad0b121d5",
            "0da35f83de3c4446a7cdcf47fab251f8",
            "9d600d60fa3e4632ba555118ecc6cd80",
            "4174b1d2166a4ea48373c22076c7df9f",
            "c8f532bdb6c747a8a6a27def3544d204",
            "03920f7d55bf49c49294768187224ce2",
            "e53e461f869b45ba937a9d0878a74aa2",
            "f82e7817016c41019b413091cbd76221",
            "96db30df7bb849d3a247116e3c68a5e3",
            "c372c8f1e20a4503af7318a548c75eac",
            "f87c0e7dd83f4e81bf459533c3f86c2b",
            "06834803cd3344a699dfa52576391af6",
            "d7f7fb4229ae454e811c3536434ada0a",
            "82284e1ed4d94d0a9624d6a7336e324d",
            "85ccb2b0d58e4d48b500caa523726e16",
            "53eec775e6794566abad421e8d01b835",
            "dea07b194b894bd98082c9e2d7c57955",
            "be000a0749be4d029db464ef56e77e26",
            "5684ca8b59dd49c387dd8e88dff68217",
            "7cbd44aaae4f4763ad1f72ea659448a1",
            "2e4e9a7d61c545a9b6d1f6e205f607a9",
            "a0872f07568e4d3cad3bdf4db1bceab7",
            "390e061a2329449d8c0147b08ebbf331",
            "6a5d97d92d0c418ab468540009a87ba8",
            "815ec7c26acb4471bbb2386063726179",
            "8a4598d5343e4e4fba7af4a5d9e66bb8",
            "3e24e34c074b497b9758a7cdd7822152",
            "989bf35c55a74e8a9102ad53843c3eb3",
            "2bcd39172c4a492aa5310bd066fe3a7a",
            "b8de403f8ed94215b07863177a701b60",
            "33a525ed6fdc4a17bbd2a4eb091e0595",
            "65f1bbb029d5459a9d32ee604ec07547",
            "35b80e612f074abb832e846fb53507c1",
            "c8594db904bf4637a5858731cde9a664",
            "06ef18534fee4a579d39b2effaa4a4e3",
            "bf891fbc02444aa7987d425665aa830a",
            "190ed816686d41b788ebde0555176c95",
            "96ed63c8f9c64f1ca610ee400ae2c5aa",
            "20e22e131612487d92827fbab7c90200",
            "db88ae59ba9e4f2b93b6bd6aee1a1e94"
          ]
        },
        "id": "PwMg2JwYSRpq",
        "outputId": "a13e84f9-65db-4b7a-e134-fad16cedeada"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cb05d151ad8497ea572b8bd3bfa88cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f17a7ec2b4c344f791453234faf927a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/90.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a4603ba9f0a4012a19a96b5bd7173ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d3d9353b4d543c39d0be7ee2ba32936",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a476002a9e344a083a1686544fd5252",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.64G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a246d0a4f28f4e6ea69ec3b2a15c0bef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de273b91d02c4802aef68f8e5bf07fa9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10b5e986a13041a382519fb1913e8e65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d3ceab287db44328653b1626bc04c2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f82e7817016c41019b413091cbd76221",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5684ca8b59dd49c387dd8e88dff68217",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8de403f8ed94215b07863177a701b60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merging done saving to google drive\n",
            "cp: '/content/drive/MyDrive/gemma-3-4b-cvpr-merged' and '/content/drive/MyDrive/gemma-3-4b-cvpr-merged' are the same file\n",
            "Merged model saved!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "base_model_name = \"google/gemma-3-4b-it\"\n",
        "adapter_path = \"gemma-3-4b-cvpr\"\n",
        "merged_model_path = \"/content/drive/MyDrive/gemma-3-4b-cvpr-merged\"\n",
        "\n",
        "# Load base\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "\n",
        "# Load + merge PEFT\n",
        "model = PeftModel.from_pretrained(base_model, adapter_path)\n",
        "model = model.merge_and_unload()\n",
        "\n",
        "# Save merged\n",
        "model.save_pretrained(merged_model_path)\n",
        "tokenizer.save_pretrained(merged_model_path)\n",
        "print(\"Merging done saving to google drive\")\n",
        "# Save to Google Drive\n",
        "!cp -r {merged_model_path} /content/drive/MyDrive/\n",
        "\n",
        "print(\"Merged model saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_EpdLicwFCS"
      },
      "outputs": [],
      "source": [
        "#zipping and downloading the folder to save progress\n",
        "from google.colab import files\n",
        "\n",
        "# The name of the folder you want to download\n",
        "folder_name = 'gemma-3-4b-cvpr'\n",
        "\n",
        "# The name of the zip file that will be created\n",
        "zip_file_name = f'{folder_name}.zip'\n",
        "\n",
        "# 1. Zip the folder\n",
        "# The '-r' flag means it will include all subdirectories and files\n",
        "!zip -r {zip_file_name} {folder_name}\n",
        "\n",
        "# 2. Download the created zip file\n",
        "files.download(zip_file_name)\n",
        "\n",
        "print(f\"Successfully zipped '{folder_name}' and initiated the download.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My1GElEj4Anv"
      },
      "source": [
        "# **Step 5: Converting the model into gguf format**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_MpUUAaolSy",
        "outputId": "957e71cd-b90e-4163-b6c2-d417659d8e52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,937 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,544 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,361 kB]\n",
            "Fetched 12.8 MB in 3s (3,662 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n"
          ]
        }
      ],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo-2n4DjrPUP",
        "outputId": "fd632bf1-9e7c-45bb-bc7a-66ac6c185573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "g++ is already the newest version (4:11.2.0-1ubuntu1).\n",
            "g++ set to manually installed.\n",
            "make is already the newest version (4.3-4.1build1).\n",
            "make set to manually installed.\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.15).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "#installing build essentials\n",
        "!apt-get install -y build-essential cmake git g++ make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fskszsKGolbs",
        "outputId": "cd3af3e0-b049-47be-f026-34a3a3722b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'llama.cpp'...\n",
            "remote: Enumerating objects: 59894, done.\u001b[K\n",
            "remote: Counting objects: 100% (153/153), done.\u001b[K\n",
            "remote: Compressing objects: 100% (93/93), done.\u001b[K\n",
            "remote: Total 59894 (delta 111), reused 60 (delta 59), pack-reused 59741 (from 4)\u001b[K\n",
            "Receiving objects: 100% (59894/59894), 157.36 MiB | 27.08 MiB/s, done.\n",
            "Resolving deltas: 100% (43079/43079), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ggerganov/llama.cpp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7o2jcYAsbAg",
        "outputId": "8337a0fa-07a3-43ee-ac28-7ee9230600f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[0mCMAKE_BUILD_TYPE=Release\u001b[0m\n",
            "-- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Warning: ccache not found - consider installing it for faster compilation or disable this warning with GGML_CCACHE=OFF\n",
            "-- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
            "-- GGML_SYSTEM_ARCH: x86\n",
            "-- Including CPU backend\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\")\n",
            "-- Found OpenMP: TRUE (found version \"4.5\")\n",
            "-- x86 detected\n",
            "-- Adding CPU backend variant ggml-cpu: -march=native \n",
            "-- ggml version: 0.0.6198\n",
            "-- ggml commit:  6d7f1117\n",
            "-- Found CURL: /usr/lib/x86_64-linux-gnu/libcurl.so (found version \"7.81.0\")\n",
            "-- Configuring done (1.6s)\n",
            "-- Generating done (0.2s)\n",
            "-- Build files have been written to: /content/llama.cpp/build\n",
            "[247/247] Linking CXX executable bin/llama-server\u001b[K\n"
          ]
        }
      ],
      "source": [
        "#building build file\n",
        "!cd llama.cpp && mkdir -p build && cd build && cmake .. -G Ninja -DLLAMA_BUILD_SERVER=ON -DLLAMA_CUDA=OFF && ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL2gwJUAnWGZ",
        "outputId": "414ea9f6-6d84-4a18-f81d-64bf0c226f01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/nightly\n",
            "Ignoring torch: markers 'platform_machine == \"s390x\"' don't match your environment\n",
            "Requirement already satisfied: mistral-common>=1.8.3 in /usr/local/lib/python3.11/dist-packages (from -r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (1.8.3)\n",
            "Requirement already satisfied: numpy~=1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: sentencepiece~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 2)) (0.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.45.1 in /usr/local/lib/python3.11/dist-packages (from -r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (4.55.2)\n",
            "Requirement already satisfied: gguf>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from -r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 4)) (0.17.1)\n",
            "Requirement already satisfied: protobuf<5.0.0,>=4.21.0 in /usr/local/lib/python3.11/dist-packages (from -r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 5)) (4.25.8)\n",
            "Requirement already satisfied: torch~=2.4.0 in /usr/local/lib/python3.11/dist-packages (from -r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 5)) (2.4.1+cpu)\n",
            "Requirement already satisfied: pydantic<3.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2.11.7)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (4.25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (11.3.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.45.1->-r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (4.67.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch~=2.4.0->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.4.0->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 5)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.4.0->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch~=2.4.0->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5.0.0,>=4.45.1->-r llama.cpp/requirements/./requirements-convert_legacy_llama.txt (line 3)) (1.1.7)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (0.27.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.7->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.7->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0,>=2.7->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: pycountry>=23 in /usr/local/lib/python3.11/dist-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (24.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->mistral-common>=1.8.3->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 1)) (2025.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.4.0->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch~=2.4.0->-r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt (line 5)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r llama.cpp/requirements/requirements-convert_hf_to_gguf.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaLGwU5Sn1nO",
        "outputId": "80ab9ce5-a5e2-4ba8-fe03-e3a31ca1dbd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:hf-to-gguf:Loading model: gemma-3-4b-cvpr-merged\n",
            "INFO:hf-to-gguf:Model architecture: Gemma3ForConditionalGeneration\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00002.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,                 torch.float16 --> F16, shape = {2560, 262208}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.0.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.0.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.0.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.0.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.1.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.1.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.1.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.1.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.10.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.10.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.10.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.10.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.11.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.11.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.11.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.11.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.12.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.12.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.12.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.12.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.13.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.13.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.13.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.13.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.14.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.14.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.2.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.2.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.2.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.2.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.3.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.3.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.3.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.3.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.4.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.4.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.4.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.4.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.5.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.5.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.5.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.5.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.6.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.6.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.6.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.6.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.7.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.7.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.7.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.7.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.8.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.8.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.8.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.8.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,             torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,             torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,               torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.9.post_attention_norm.weight,  torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.9.post_ffw_norm.weight,        torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,             torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.9.attn_k_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,          torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.9.attn_q_norm.weight,          torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,               torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,               torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00002.safetensors'\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.14.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.14.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.15.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.15.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.15.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.15.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.16.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.16.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.16.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.16.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.17.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.17.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.17.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.17.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.18.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.18.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.18.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.18.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.19.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.19.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.19.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.19.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.20.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.20.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.20.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.20.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.21.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.21.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.21.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.21.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.22.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.22.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.22.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.22.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.23.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.23.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.23.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.23.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.24.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.24.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.24.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.24.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.25.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.25.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.25.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.25.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.26.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.26.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.26.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.26.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.27.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.27.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.27.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.27.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.28.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.28.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.28.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.28.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.29.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.29.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.29.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.29.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.30.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.30.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.30.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.30.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.31.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.31.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.31.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.31.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.32.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.32.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.32.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.32.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.32.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.32.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.32.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.32.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.32.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.32.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.32.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.32.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.32.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.33.attn_norm.weight,           torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.33.ffn_down.weight,            torch.float16 --> F16, shape = {10240, 2560}\n",
            "INFO:hf-to-gguf:blk.33.ffn_gate.weight,            torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.33.ffn_up.weight,              torch.float16 --> F16, shape = {2560, 10240}\n",
            "INFO:hf-to-gguf:blk.33.post_attention_norm.weight, torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.33.post_ffw_norm.weight,       torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.33.ffn_norm.weight,            torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:blk.33.attn_k_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.33.attn_k.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:blk.33.attn_output.weight,         torch.float16 --> F16, shape = {2048, 2560}\n",
            "INFO:hf-to-gguf:blk.33.attn_q_norm.weight,         torch.float16 --> F32, shape = {256}\n",
            "INFO:hf-to-gguf:blk.33.attn_q.weight,              torch.float16 --> F16, shape = {2560, 2048}\n",
            "INFO:hf-to-gguf:blk.33.attn_v.weight,              torch.float16 --> F16, shape = {2560, 1024}\n",
            "INFO:hf-to-gguf:output_norm.weight,                torch.float16 --> F32, shape = {2560}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "WARNING:gguf.vocab:Unknown separator token '<bos>' in TemplateProcessing<pair>\n",
            "INFO:gguf.vocab:Setting special token type bos to 2\n",
            "INFO:gguf.vocab:Setting special token type eos to 1\n",
            "INFO:gguf.vocab:Setting special token type unk to 3\n",
            "INFO:gguf.vocab:Setting special token type pad to 0\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_sep_token to False\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {{ bos_token }}\n",
            "{%- if messages[0]['role'] == 'system' -%}\n",
            "    {%- if messages[0]['content'] is string -%}\n",
            "        {%- set first_user_prefix = messages[0]['content'] + '\n",
            "\n",
            "' -%}\n",
            "    {%- else -%}\n",
            "        {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\n",
            "\n",
            "' -%}\n",
            "    {%- endif -%}\n",
            "    {%- set loop_messages = messages[1:] -%}\n",
            "{%- else -%}\n",
            "    {%- set first_user_prefix = \"\" -%}\n",
            "    {%- set loop_messages = messages -%}\n",
            "{%- endif -%}\n",
            "{%- for message in loop_messages -%}\n",
            "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n",
            "        {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
            "    {%- endif -%}\n",
            "    {%- if (message['role'] == 'assistant') -%}\n",
            "        {%- set role = \"model\" -%}\n",
            "    {%- else -%}\n",
            "        {%- set role = message['role'] -%}\n",
            "    {%- endif -%}\n",
            "    {{ '<start_of_turn>' + role + '\n",
            "' + (first_user_prefix if loop.first else \"\") }}\n",
            "    {%- if message['content'] is string -%}\n",
            "        {{ message['content'] | trim }}\n",
            "    {%- elif message['content'] is iterable -%}\n",
            "        {%- for item in message['content'] -%}\n",
            "            {%- if item['type'] == 'image' -%}\n",
            "                {{ '<start_of_image>' }}\n",
            "            {%- elif item['type'] == 'text' -%}\n",
            "                {{ item['text'] | trim }}\n",
            "            {%- endif -%}\n",
            "        {%- endfor -%}\n",
            "    {%- else -%}\n",
            "        {{ raise_exception(\"Invalid content type\") }}\n",
            "    {%- endif -%}\n",
            "    {{ '<end_of_turn>\n",
            "' }}\n",
            "{%- endfor -%}\n",
            "{%- if add_generation_prompt -%}\n",
            "    {{'<start_of_turn>model\n",
            "'}}\n",
            "{%- endif -%}\n",
            "\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/gemma-3-4b-cvpr-f16.gguf: n_tensors = 444, total_size = 7.8G\n",
            "Writing: 100% 7.76G/7.76G [01:26<00:00, 89.4Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/gemma-3-4b-cvpr-f16.gguf\n"
          ]
        }
      ],
      "source": [
        "#Converting the model into gguf fomat along with dequantization to 16 bit\n",
        "!python llama.cpp/convert_hf_to_gguf.py /content/drive/MyDrive/gemma-3-4b-cvpr-merged --outfile /content/gemma-3-4b-cvpr-f16.gguf --outtype f16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA5VNt_rsbEZ",
        "outputId": "014083b8-aa76-44fa-9d3c-fe3c4edadc0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rwxr-xr-x 1 root root 355K Aug 18 19:49 llama.cpp/build/bin/llama-quantize\n"
          ]
        }
      ],
      "source": [
        "!ls -lh llama.cpp/build/bin/llama-quantize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaPBLGUMsbLm",
        "outputId": "62f303f7-88bd-4f3b-ad35-5e983cea6daf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "main: build = 6198 (6d7f1117)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/drive/MyDrive/gemma-3-4b-cvpr-f16.gguf' to '/content/drive/MyDrive/gemma-3-4b-cvpr-q4_k_m.gguf' as Q4_K_M\n",
            "llama_model_loader: loaded meta data with 35 key-value pairs and 444 tensors from /content/drive/MyDrive/gemma-3-4b-cvpr-f16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gemma3\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gemma 3 4b Cvpr Merged\n",
            "llama_model_loader: - kv   3:                           general.finetune str              = cvpr-merged\n",
            "llama_model_loader: - kv   4:                           general.basename str              = gemma-3\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 4B\n",
            "llama_model_loader: - kv   6:                      gemma3.context_length u32              = 131072\n",
            "llama_model_loader: - kv   7:                    gemma3.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv   8:                         gemma3.block_count u32              = 34\n",
            "llama_model_loader: - kv   9:                 gemma3.feed_forward_length u32              = 10240\n",
            "llama_model_loader: - kv  10:                gemma3.attention.head_count u32              = 8\n",
            "llama_model_loader: - kv  11:    gemma3.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  12:                gemma3.attention.key_length u32              = 256\n",
            "llama_model_loader: - kv  13:              gemma3.attention.value_length u32              = 256\n",
            "llama_model_loader: - kv  14:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  15:                      gemma3.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  16:            gemma3.attention.sliding_window u32              = 1024\n",
            "llama_model_loader: - kv  17:             gemma3.attention.head_count_kv u32              = 4\n",
            "llama_model_loader: - kv  18:                   gemma3.rope.scaling.type str              = linear\n",
            "llama_model_loader: - kv  19:                 gemma3.rope.scaling.factor f32              = 8.000000\n",
            "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  21:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,262208]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.scores arr[f32,262208]  = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,262208]  = [3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, ...\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 2\n",
            "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 1\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 3\n",
            "llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  31:               tokenizer.ggml.add_sep_token bool             = false\n",
            "llama_model_loader: - kv  32:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  33:                    tokenizer.chat_template str              = {{ bos_token }}\\n{%- if messages[0]['r...\n",
            "llama_model_loader: - kv  34:            tokenizer.ggml.add_space_prefix bool             = false\n",
            "llama_model_loader: - type  f32:  205 tensors\n",
            "llama_model_loader: - type  f16:  239 tensors\n",
            "[   1/ 444]                   output_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   2/ 444]                    token_embd.weight - [ 2560, 262208,     1,     1], type =    f16, converting to q6_K .. size =  1280.31 MiB ->   525.13 MiB\n",
            "[   3/ 444]                  blk.0.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[   4/ 444]             blk.0.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[   5/ 444]               blk.0.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[   6/ 444]             blk.0.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[   7/ 444]                  blk.0.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[   8/ 444]             blk.0.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[   9/ 444]                  blk.0.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  10/ 444]                blk.0.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  11/ 444]                blk.0.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  12/ 444]                blk.0.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  13/ 444]                  blk.0.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  14/ 444]     blk.0.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  15/ 444]           blk.0.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  16/ 444]                  blk.1.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  17/ 444]             blk.1.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  18/ 444]               blk.1.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  19/ 444]             blk.1.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  20/ 444]                  blk.1.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  21/ 444]             blk.1.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  22/ 444]                  blk.1.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  23/ 444]                blk.1.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  24/ 444]                blk.1.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  25/ 444]                blk.1.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  26/ 444]                  blk.1.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  27/ 444]     blk.1.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  28/ 444]           blk.1.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  29/ 444]                  blk.2.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  30/ 444]             blk.2.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  31/ 444]               blk.2.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  32/ 444]             blk.2.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  33/ 444]                  blk.2.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  34/ 444]             blk.2.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  35/ 444]                  blk.2.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  36/ 444]                blk.2.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  37/ 444]                blk.2.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  38/ 444]                blk.2.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  39/ 444]                  blk.2.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  40/ 444]     blk.2.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  41/ 444]           blk.2.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  42/ 444]                  blk.3.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  43/ 444]             blk.3.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  44/ 444]               blk.3.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  45/ 444]             blk.3.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  46/ 444]                  blk.3.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  47/ 444]             blk.3.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  48/ 444]                  blk.3.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  49/ 444]                blk.3.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  50/ 444]                blk.3.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  51/ 444]                blk.3.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  52/ 444]                  blk.3.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  53/ 444]     blk.3.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  54/ 444]           blk.3.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  55/ 444]                  blk.4.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  56/ 444]             blk.4.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  57/ 444]               blk.4.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  58/ 444]             blk.4.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  59/ 444]                  blk.4.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  60/ 444]             blk.4.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  61/ 444]                  blk.4.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  62/ 444]                blk.4.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  63/ 444]                blk.4.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  64/ 444]                blk.4.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  65/ 444]                  blk.4.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  66/ 444]     blk.4.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  67/ 444]           blk.4.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  68/ 444]                  blk.5.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  69/ 444]             blk.5.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  70/ 444]               blk.5.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  71/ 444]             blk.5.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  72/ 444]                  blk.5.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  73/ 444]             blk.5.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  74/ 444]                  blk.5.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  75/ 444]                blk.5.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  76/ 444]                blk.5.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  77/ 444]                blk.5.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  78/ 444]                  blk.5.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  79/ 444]     blk.5.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  80/ 444]           blk.5.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  81/ 444]                  blk.6.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  82/ 444]             blk.6.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  83/ 444]               blk.6.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  84/ 444]             blk.6.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  85/ 444]                  blk.6.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  86/ 444]             blk.6.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  87/ 444]                  blk.6.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[  88/ 444]                blk.6.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[  89/ 444]                blk.6.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  90/ 444]                blk.6.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  91/ 444]                  blk.6.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[  92/ 444]     blk.6.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  93/ 444]           blk.6.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  94/ 444]                  blk.7.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[  95/ 444]             blk.7.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[  96/ 444]               blk.7.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[  97/ 444]             blk.7.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  98/ 444]                  blk.7.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[  99/ 444]             blk.7.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 100/ 444]                  blk.7.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 101/ 444]                blk.7.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 102/ 444]                blk.7.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 103/ 444]                blk.7.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 104/ 444]                  blk.7.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 105/ 444]     blk.7.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 106/ 444]           blk.7.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 107/ 444]                  blk.8.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 108/ 444]             blk.8.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 109/ 444]               blk.8.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 110/ 444]             blk.8.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 111/ 444]                  blk.8.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 112/ 444]             blk.8.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 113/ 444]                  blk.8.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 114/ 444]                blk.8.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 115/ 444]                blk.8.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 116/ 444]                blk.8.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 117/ 444]                  blk.8.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 118/ 444]     blk.8.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 119/ 444]           blk.8.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 120/ 444]                  blk.9.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 121/ 444]             blk.9.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 122/ 444]               blk.9.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 123/ 444]             blk.9.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 124/ 444]                  blk.9.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 125/ 444]             blk.9.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 126/ 444]                  blk.9.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 127/ 444]                blk.9.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 128/ 444]                blk.9.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 129/ 444]                blk.9.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 130/ 444]                  blk.9.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 131/ 444]     blk.9.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 132/ 444]           blk.9.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 133/ 444]                 blk.10.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 134/ 444]            blk.10.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 135/ 444]              blk.10.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 136/ 444]            blk.10.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 137/ 444]                 blk.10.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 138/ 444]            blk.10.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 139/ 444]                 blk.10.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 140/ 444]               blk.10.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 141/ 444]               blk.10.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 142/ 444]               blk.10.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 143/ 444]                 blk.10.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 144/ 444]    blk.10.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 145/ 444]          blk.10.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 146/ 444]                 blk.11.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 147/ 444]            blk.11.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 148/ 444]              blk.11.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 149/ 444]            blk.11.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 150/ 444]                 blk.11.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 151/ 444]            blk.11.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 152/ 444]                 blk.11.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 153/ 444]               blk.11.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 154/ 444]               blk.11.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 155/ 444]               blk.11.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 156/ 444]                 blk.11.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 157/ 444]    blk.11.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 158/ 444]          blk.11.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 159/ 444]                 blk.12.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 160/ 444]            blk.12.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 161/ 444]              blk.12.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 162/ 444]            blk.12.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 163/ 444]                 blk.12.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 164/ 444]            blk.12.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 165/ 444]                 blk.12.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 166/ 444]               blk.12.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 167/ 444]               blk.12.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 168/ 444]               blk.12.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 169/ 444]                 blk.12.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 170/ 444]    blk.12.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 171/ 444]          blk.12.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 172/ 444]                 blk.13.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 173/ 444]            blk.13.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 174/ 444]              blk.13.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 175/ 444]            blk.13.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 176/ 444]                 blk.13.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 177/ 444]            blk.13.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 178/ 444]                 blk.13.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 179/ 444]               blk.13.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 180/ 444]               blk.13.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 181/ 444]               blk.13.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 182/ 444]                 blk.13.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 183/ 444]    blk.13.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 184/ 444]          blk.13.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 185/ 444]                 blk.14.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 186/ 444]            blk.14.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 187/ 444]              blk.14.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 188/ 444]            blk.14.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 189/ 444]                 blk.14.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 190/ 444]            blk.14.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 191/ 444]                 blk.14.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 192/ 444]               blk.14.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 193/ 444]               blk.14.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 194/ 444]               blk.14.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 195/ 444]                 blk.14.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 196/ 444]    blk.14.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 197/ 444]          blk.14.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 198/ 444]                 blk.15.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 199/ 444]            blk.15.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 200/ 444]              blk.15.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 201/ 444]            blk.15.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 202/ 444]                 blk.15.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 203/ 444]            blk.15.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 204/ 444]                 blk.15.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 205/ 444]               blk.15.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 206/ 444]               blk.15.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 207/ 444]               blk.15.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 208/ 444]                 blk.15.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 209/ 444]    blk.15.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 210/ 444]          blk.15.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 211/ 444]                 blk.16.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 212/ 444]            blk.16.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 213/ 444]              blk.16.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 214/ 444]            blk.16.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 215/ 444]                 blk.16.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 216/ 444]            blk.16.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 217/ 444]                 blk.16.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 218/ 444]               blk.16.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 219/ 444]               blk.16.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 220/ 444]               blk.16.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 221/ 444]                 blk.16.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 222/ 444]    blk.16.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 223/ 444]          blk.16.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 224/ 444]                 blk.17.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 225/ 444]            blk.17.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 226/ 444]              blk.17.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 227/ 444]            blk.17.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 228/ 444]                 blk.17.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 229/ 444]            blk.17.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 230/ 444]                 blk.17.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 231/ 444]               blk.17.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 232/ 444]               blk.17.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 233/ 444]               blk.17.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 234/ 444]                 blk.17.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 235/ 444]    blk.17.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 236/ 444]          blk.17.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 237/ 444]                 blk.18.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 238/ 444]            blk.18.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 239/ 444]              blk.18.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 240/ 444]            blk.18.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 241/ 444]                 blk.18.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 242/ 444]            blk.18.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 243/ 444]                 blk.18.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 244/ 444]               blk.18.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 245/ 444]               blk.18.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 246/ 444]               blk.18.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 247/ 444]                 blk.18.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 248/ 444]    blk.18.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 249/ 444]          blk.18.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 250/ 444]                 blk.19.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 251/ 444]            blk.19.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 252/ 444]              blk.19.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 253/ 444]            blk.19.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 254/ 444]                 blk.19.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 255/ 444]            blk.19.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 256/ 444]                 blk.19.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 257/ 444]               blk.19.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 258/ 444]               blk.19.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 259/ 444]               blk.19.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 260/ 444]                 blk.19.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 261/ 444]    blk.19.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 262/ 444]          blk.19.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 263/ 444]                 blk.20.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 264/ 444]            blk.20.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 265/ 444]              blk.20.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 266/ 444]            blk.20.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 267/ 444]                 blk.20.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 268/ 444]            blk.20.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 269/ 444]                 blk.20.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 270/ 444]               blk.20.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 271/ 444]               blk.20.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 272/ 444]               blk.20.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 273/ 444]                 blk.20.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 274/ 444]    blk.20.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 275/ 444]          blk.20.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 276/ 444]                 blk.21.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 277/ 444]            blk.21.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 278/ 444]              blk.21.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 279/ 444]            blk.21.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 280/ 444]                 blk.21.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 281/ 444]            blk.21.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 282/ 444]                 blk.21.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 283/ 444]               blk.21.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 284/ 444]               blk.21.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 285/ 444]               blk.21.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 286/ 444]                 blk.21.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 287/ 444]    blk.21.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 288/ 444]          blk.21.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 289/ 444]                 blk.22.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 290/ 444]            blk.22.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 291/ 444]              blk.22.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 292/ 444]            blk.22.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 293/ 444]                 blk.22.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 294/ 444]            blk.22.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 295/ 444]                 blk.22.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 296/ 444]               blk.22.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 297/ 444]               blk.22.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 298/ 444]               blk.22.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 299/ 444]                 blk.22.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 300/ 444]    blk.22.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 301/ 444]          blk.22.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 302/ 444]                 blk.23.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 303/ 444]            blk.23.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 304/ 444]              blk.23.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 305/ 444]            blk.23.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 306/ 444]                 blk.23.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 307/ 444]            blk.23.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 308/ 444]                 blk.23.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 309/ 444]               blk.23.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 310/ 444]               blk.23.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 311/ 444]               blk.23.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 312/ 444]                 blk.23.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 313/ 444]    blk.23.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 314/ 444]          blk.23.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 315/ 444]                 blk.24.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 316/ 444]            blk.24.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 317/ 444]              blk.24.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 318/ 444]            blk.24.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 319/ 444]                 blk.24.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 320/ 444]            blk.24.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 321/ 444]                 blk.24.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 322/ 444]               blk.24.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 323/ 444]               blk.24.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 324/ 444]               blk.24.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 325/ 444]                 blk.24.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 326/ 444]    blk.24.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 327/ 444]          blk.24.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 328/ 444]                 blk.25.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 329/ 444]            blk.25.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 330/ 444]              blk.25.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 331/ 444]            blk.25.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 332/ 444]                 blk.25.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 333/ 444]            blk.25.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 334/ 444]                 blk.25.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 335/ 444]               blk.25.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 336/ 444]               blk.25.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 337/ 444]               blk.25.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 338/ 444]                 blk.25.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 339/ 444]    blk.25.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 340/ 444]          blk.25.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 341/ 444]                 blk.26.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 342/ 444]            blk.26.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 343/ 444]              blk.26.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 344/ 444]            blk.26.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 345/ 444]                 blk.26.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 346/ 444]            blk.26.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 347/ 444]                 blk.26.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 348/ 444]               blk.26.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 349/ 444]               blk.26.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 350/ 444]               blk.26.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 351/ 444]                 blk.26.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 352/ 444]    blk.26.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 353/ 444]          blk.26.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 354/ 444]                 blk.27.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 355/ 444]            blk.27.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 356/ 444]              blk.27.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 357/ 444]            blk.27.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 358/ 444]                 blk.27.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 359/ 444]            blk.27.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 360/ 444]                 blk.27.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 361/ 444]               blk.27.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 362/ 444]               blk.27.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 363/ 444]               blk.27.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 364/ 444]                 blk.27.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 365/ 444]    blk.27.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 366/ 444]          blk.27.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 367/ 444]                 blk.28.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 368/ 444]            blk.28.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 369/ 444]              blk.28.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 370/ 444]            blk.28.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 371/ 444]                 blk.28.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 372/ 444]            blk.28.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 373/ 444]                 blk.28.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 374/ 444]               blk.28.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 375/ 444]               blk.28.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 376/ 444]               blk.28.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 377/ 444]                 blk.28.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 378/ 444]    blk.28.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 379/ 444]          blk.28.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 380/ 444]                 blk.29.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 381/ 444]            blk.29.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 382/ 444]              blk.29.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 383/ 444]            blk.29.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 384/ 444]                 blk.29.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 385/ 444]            blk.29.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 386/ 444]                 blk.29.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 387/ 444]               blk.29.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 388/ 444]               blk.29.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 389/ 444]               blk.29.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 390/ 444]                 blk.29.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 391/ 444]    blk.29.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 392/ 444]          blk.29.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 393/ 444]                 blk.30.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 394/ 444]            blk.30.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 395/ 444]              blk.30.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 396/ 444]            blk.30.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 397/ 444]                 blk.30.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 398/ 444]            blk.30.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 399/ 444]                 blk.30.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 400/ 444]               blk.30.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 401/ 444]               blk.30.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 402/ 444]               blk.30.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 403/ 444]                 blk.30.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 404/ 444]    blk.30.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 405/ 444]          blk.30.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 406/ 444]                 blk.31.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 407/ 444]            blk.31.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 408/ 444]              blk.31.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 409/ 444]            blk.31.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 410/ 444]                 blk.31.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 411/ 444]            blk.31.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 412/ 444]                 blk.31.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 413/ 444]               blk.31.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 414/ 444]               blk.31.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 415/ 444]               blk.31.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 416/ 444]                 blk.31.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 417/ 444]    blk.31.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 418/ 444]          blk.31.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 419/ 444]                 blk.32.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 420/ 444]            blk.32.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 421/ 444]              blk.32.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 422/ 444]            blk.32.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 423/ 444]                 blk.32.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 424/ 444]            blk.32.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 425/ 444]                 blk.32.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 426/ 444]               blk.32.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 427/ 444]               blk.32.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 428/ 444]               blk.32.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 429/ 444]                 blk.32.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 430/ 444]    blk.32.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 431/ 444]          blk.32.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 432/ 444]                 blk.33.attn_k.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q4_K .. size =     5.00 MiB ->     1.41 MiB\n",
            "[ 433/ 444]            blk.33.attn_k_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 434/ 444]              blk.33.attn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 435/ 444]            blk.33.attn_output.weight - [ 2048,  2560,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 436/ 444]                 blk.33.attn_q.weight - [ 2560,  2048,     1,     1], type =    f16, converting to q4_K .. size =    10.00 MiB ->     2.81 MiB\n",
            "[ 437/ 444]            blk.33.attn_q_norm.weight - [  256,     1,     1,     1], type =    f32, size =    0.001 MB\n",
            "[ 438/ 444]                 blk.33.attn_v.weight - [ 2560,  1024,     1,     1], type =    f16, converting to q6_K .. size =     5.00 MiB ->     2.05 MiB\n",
            "[ 439/ 444]               blk.33.ffn_down.weight - [10240,  2560,     1,     1], type =    f16, converting to q6_K .. size =    50.00 MiB ->    20.51 MiB\n",
            "[ 440/ 444]               blk.33.ffn_gate.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 441/ 444]               blk.33.ffn_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 442/ 444]                 blk.33.ffn_up.weight - [ 2560, 10240,     1,     1], type =    f16, converting to q4_K .. size =    50.00 MiB ->    14.06 MiB\n",
            "[ 443/ 444]    blk.33.post_attention_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "[ 444/ 444]          blk.33.post_ffw_norm.weight - [ 2560,     1,     1,     1], type =    f32, size =    0.010 MB\n",
            "llama_model_quantize_impl: model size  =  7401.72 MB\n",
            "llama_model_quantize_impl: quant size  =  2368.31 MB\n",
            "\n",
            "main: quantize time = 401763.68 ms\n",
            "main:    total time = 401763.68 ms\n"
          ]
        }
      ],
      "source": [
        "#Converting the 16 bit gguf formatted model to 4 bit gguf formatted model\n",
        "!llama.cpp/build/bin/llama-quantize /content/drive/MyDrive/gemma-3-4b-cvpr-f16.gguf /content/drive/MyDrive/gemma-3-4b-cvpr-q4_k_m.gguf q4_k_m"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00794e9f77c74bedbae4d917e90667e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00e115db6d5b417abc38a3b2f86a4c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85ddfa0895e746ea93f8639c4e14cb99",
            "placeholder": "​",
            "style": "IPY_MODEL_fc1038d1ad554865996b57172569a661",
            "value": " 2/2 [00:38&lt;00:00, 18.81s/it]"
          }
        },
        "0124a88b488940608d490e2ea8c99b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15f8687038ec48f0b5b119eced928ced",
            "placeholder": "​",
            "style": "IPY_MODEL_f6f521772d21415da8ba911b73707819",
            "value": "Fetching 2 files: 100%"
          }
        },
        "028b8c03ee9f4e219ffab1911fd8d5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_528a572c56934083936662ee044cd0d3",
            "max": 90558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0fe80ffb3fc34647a3581605fbd07df6",
            "value": 90558
          }
        },
        "03920f7d55bf49c49294768187224ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0574e85d4ba2425b8f1cdd02aea40891": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff5b5ce5ed1149ff81de93277bc1b902",
            "placeholder": "​",
            "style": "IPY_MODEL_9cfaf769a7ff4859b14e64bbb2e64016",
            "value": "config.json: 100%"
          }
        },
        "06834803cd3344a699dfa52576391af6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ef18534fee4a579d39b2effaa4a4e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ea2b75483e4bac927555ec0278cd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dad0d502d9e4395a6915ffaedd2bea4",
            "placeholder": "​",
            "style": "IPY_MODEL_b92440c3d37144d79580ab3e2ed2c760",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "0912a475313f4ae9893673866bb55920": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef81a31613bc417a80f426af81991d83",
            "placeholder": "​",
            "style": "IPY_MODEL_fec0b860a5114a9b848a4c1c76db2b8b",
            "value": " 90.6k/90.6k [00:00&lt;00:00, 758kB/s]"
          }
        },
        "0b522798f5884631b8ddc5190c11ec47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0da35f83de3c4446a7cdcf47fab251f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ddcc2dfd6c540e3a49bfc11f5a59e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f2b28f6a1394430a30ab24238f29af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0b39f3de8b44f05810159bb8a616147",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b522798f5884631b8ddc5190c11ec47",
            "value": 2
          }
        },
        "0fe80ffb3fc34647a3581605fbd07df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "100776baf73e44faa0c72863b21dbe81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10b5e986a13041a382519fb1913e8e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c7c324abfce4a15bce105b0eb4137be",
              "IPY_MODEL_d9e52e21643c430a9041f3d2954f1357",
              "IPY_MODEL_6dac6837cbc54cb7bdddd16e2fb7fe4b"
            ],
            "layout": "IPY_MODEL_1c74c9a02c81407ba254560f21411f5d"
          }
        },
        "119758192f464254817372255e315ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "130a4b12e6454e8fb24cf4494b7da68e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15f8687038ec48f0b5b119eced928ced": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "190ed816686d41b788ebde0555176c95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af245da1b394ccba723c8b2cb4c8d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b61231cd91449ada00d7a11d0e7dfe5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c08b3c90e3d42bd8747fd96ca3d8e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0da35f83de3c4446a7cdcf47fab251f8",
            "placeholder": "​",
            "style": "IPY_MODEL_9d600d60fa3e4632ba555118ecc6cd80",
            "value": "tokenizer.model: 100%"
          }
        },
        "1c74c9a02c81407ba254560f21411f5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d3ceab287db44328653b1626bc04c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c08b3c90e3d42bd8747fd96ca3d8e1c",
              "IPY_MODEL_8b47b2ddfe8442838a88ce54fab3957b",
              "IPY_MODEL_8d1c1e5a844047c8b1d59d42acd5c66f"
            ],
            "layout": "IPY_MODEL_905b637c9d714680bf35c53ad0b121d5"
          }
        },
        "20e22e131612487d92827fbab7c90200": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "215a19cc49054acd9afbfd2a215b6e6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "279b09dcc33b4089aba54910b7ddd8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a4603ba9f0a4012a19a96b5bd7173ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0124a88b488940608d490e2ea8c99b19",
              "IPY_MODEL_0f2b28f6a1394430a30ab24238f29af1",
              "IPY_MODEL_ed8ac87f09b4470d814778580d7d0127"
            ],
            "layout": "IPY_MODEL_b1efd115ab81498c96ee9e98aef96777"
          }
        },
        "2bcd39172c4a492aa5310bd066fe3a7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e4e9a7d61c545a9b6d1f6e205f607a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4598d5343e4e4fba7af4a5d9e66bb8",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e24e34c074b497b9758a7cdd7822152",
            "value": 35
          }
        },
        "3174e818e510457a821b0563dcd70bce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd900cd1975e4baead05350f82017293",
            "max": 215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b14970f68604a8087011a00d3db20c4",
            "value": 215
          }
        },
        "33a525ed6fdc4a17bbd2a4eb091e0595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ef18534fee4a579d39b2effaa4a4e3",
            "placeholder": "​",
            "style": "IPY_MODEL_bf891fbc02444aa7987d425665aa830a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "35b80e612f074abb832e846fb53507c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20e22e131612487d92827fbab7c90200",
            "placeholder": "​",
            "style": "IPY_MODEL_db88ae59ba9e4f2b93b6bd6aee1a1e94",
            "value": " 662/662 [00:00&lt;00:00, 64.8kB/s]"
          }
        },
        "3795615b2cab4189966699aba3f263d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390e061a2329449d8c0147b08ebbf331": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e24e34c074b497b9758a7cdd7822152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ff6f2769e154ea6a51f4afdb752f2a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4004b7635d544e59ba2ffe3297c8e983": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4174b1d2166a4ea48373c22076c7df9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49926dd314b74d4b9e655c5175e405e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "528a572c56934083936662ee044cd0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53eec775e6794566abad421e8d01b835": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5684ca8b59dd49c387dd8e88dff68217": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cbd44aaae4f4763ad1f72ea659448a1",
              "IPY_MODEL_2e4e9a7d61c545a9b6d1f6e205f607a9",
              "IPY_MODEL_a0872f07568e4d3cad3bdf4db1bceab7"
            ],
            "layout": "IPY_MODEL_390e061a2329449d8c0147b08ebbf331"
          }
        },
        "5d3d9353b4d543c39d0be7ee2ba32936": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfcab6dc6e7842fcaa03590a0b935d83",
              "IPY_MODEL_d242a9860a274c2fbbed28e382dee554",
              "IPY_MODEL_962c4dfab86742019773ebe19e3b3aae"
            ],
            "layout": "IPY_MODEL_9e99e578d4b54e7e9bdfb99e7cac6f62"
          }
        },
        "5d4389c6344049399dd3f8f683d83403": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62843bdfcca44405a598193402527a00": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f1bbb029d5459a9d32ee604ec07547": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_190ed816686d41b788ebde0555176c95",
            "max": 662,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96ed63c8f9c64f1ca610ee400ae2c5aa",
            "value": 662
          }
        },
        "6a476002a9e344a083a1686544fd5252": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd87846c577b4f2a9ff66c112b772b12",
              "IPY_MODEL_eef9d3e14c804c86b668f9a4eaff141d",
              "IPY_MODEL_bd0f8e4f2cc0431dac0bee226af41415"
            ],
            "layout": "IPY_MODEL_db8740ca76e34a85b90c898ccd952ff8"
          }
        },
        "6a5d97d92d0c418ab468540009a87ba8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dac6837cbc54cb7bdddd16e2fb7fe4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49926dd314b74d4b9e655c5175e405e1",
            "placeholder": "​",
            "style": "IPY_MODEL_a08623735f7949759c9e870bcc4aa893",
            "value": " 1.16M/1.16M [00:00&lt;00:00, 6.17MB/s]"
          }
        },
        "6f04c0dddb1a4723a131f17e31f278ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00794e9f77c74bedbae4d917e90667e5",
            "max": 855,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_130a4b12e6454e8fb24cf4494b7da68e",
            "value": 855
          }
        },
        "72f0e99faddf4bc5859d0938febcaaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "74957acb3c60499b9a1a366f6c9c9db6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b14970f68604a8087011a00d3db20c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c7c324abfce4a15bce105b0eb4137be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62843bdfcca44405a598193402527a00",
            "placeholder": "​",
            "style": "IPY_MODEL_f7c6eff3034d4e25aafef35ef8c187cf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7cb05d151ad8497ea572b8bd3bfa88cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0574e85d4ba2425b8f1cdd02aea40891",
              "IPY_MODEL_6f04c0dddb1a4723a131f17e31f278ba",
              "IPY_MODEL_dfac8a771d85424da4bca9f327dbc656"
            ],
            "layout": "IPY_MODEL_d8725c4a0f3c4ee495545eb4f0f69944"
          }
        },
        "7cbd44aaae4f4763ad1f72ea659448a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a5d97d92d0c418ab468540009a87ba8",
            "placeholder": "​",
            "style": "IPY_MODEL_815ec7c26acb4471bbb2386063726179",
            "value": "added_tokens.json: 100%"
          }
        },
        "815ec7c26acb4471bbb2386063726179": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82284e1ed4d94d0a9624d6a7336e324d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85ccb2b0d58e4d48b500caa523726e16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ddfa0895e746ea93f8639c4e14cb99": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4598d5343e4e4fba7af4a5d9e66bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b47b2ddfe8442838a88ce54fab3957b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4174b1d2166a4ea48373c22076c7df9f",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8f532bdb6c747a8a6a27def3544d204",
            "value": 4689074
          }
        },
        "8d1c1e5a844047c8b1d59d42acd5c66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03920f7d55bf49c49294768187224ce2",
            "placeholder": "​",
            "style": "IPY_MODEL_e53e461f869b45ba937a9d0878a74aa2",
            "value": " 4.69M/4.69M [00:00&lt;00:00, 246kB/s]"
          }
        },
        "8dad0d502d9e4395a6915ffaedd2bea4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "905b637c9d714680bf35c53ad0b121d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95c7648da0044dd0bba816eb43d813d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3df2b0087124db6984ec75b52fb03ea",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5bbe08b521d438b9047935cfa6ea71e",
            "value": 2
          }
        },
        "962c4dfab86742019773ebe19e3b3aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d4389c6344049399dd3f8f683d83403",
            "placeholder": "​",
            "style": "IPY_MODEL_e31c5edada3b484b907a51077a05d288",
            "value": " 4.96G/4.96G [06:03&lt;00:00, 66.3MB/s]"
          }
        },
        "96db30df7bb849d3a247116e3c68a5e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7f7fb4229ae454e811c3536434ada0a",
            "placeholder": "​",
            "style": "IPY_MODEL_82284e1ed4d94d0a9624d6a7336e324d",
            "value": "tokenizer.json: 100%"
          }
        },
        "96ed63c8f9c64f1ca610ee400ae2c5aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "989bf35c55a74e8a9102ad53843c3eb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c73151b544044d9af59e2057cf1e5a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cfaf769a7ff4859b14e64bbb2e64016": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d600d60fa3e4632ba555118ecc6cd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9df4d7143c8f451a9bb89de45d322ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e99e578d4b54e7e9bdfb99e7cac6f62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a08623735f7949759c9e870bcc4aa893": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0872f07568e4d3cad3bdf4db1bceab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_989bf35c55a74e8a9102ad53843c3eb3",
            "placeholder": "​",
            "style": "IPY_MODEL_2bcd39172c4a492aa5310bd066fe3a7a",
            "value": " 35.0/35.0 [00:00&lt;00:00, 3.74kB/s]"
          }
        },
        "a246d0a4f28f4e6ea69ec3b2a15c0bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba67e4c09df84e809619c790f71546ac",
              "IPY_MODEL_95c7648da0044dd0bba816eb43d813d2",
              "IPY_MODEL_00e115db6d5b417abc38a3b2f86a4c04"
            ],
            "layout": "IPY_MODEL_0ddcc2dfd6c540e3a49bfc11f5a59e9f"
          }
        },
        "a3b25709c62942b2bf56e6a726417e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5bbe08b521d438b9047935cfa6ea71e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1efd115ab81498c96ee9e98aef96777": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5604d12090646df905d25a536d7f2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8de403f8ed94215b07863177a701b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33a525ed6fdc4a17bbd2a4eb091e0595",
              "IPY_MODEL_65f1bbb029d5459a9d32ee604ec07547",
              "IPY_MODEL_35b80e612f074abb832e846fb53507c1"
            ],
            "layout": "IPY_MODEL_c8594db904bf4637a5858731cde9a664"
          }
        },
        "b92440c3d37144d79580ab3e2ed2c760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba67e4c09df84e809619c790f71546ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c73151b544044d9af59e2057cf1e5a0",
            "placeholder": "​",
            "style": "IPY_MODEL_4004b7635d544e59ba2ffe3297c8e983",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "baa1c14c050740daac3c66a8a870c9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd0f8e4f2cc0431dac0bee226af41415": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f855a6c300ca481a92347176780a720b",
            "placeholder": "​",
            "style": "IPY_MODEL_1af245da1b394ccba723c8b2cb4c8d36",
            "value": " 3.64G/3.64G [05:39&lt;00:00, 2.99MB/s]"
          }
        },
        "be000a0749be4d029db464ef56e77e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bec1c667580e4658bca78ce615106488": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf891fbc02444aa7987d425665aa830a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0bd159a46c441648f1f6fa0bf1fef7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c372c8f1e20a4503af7318a548c75eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85ccb2b0d58e4d48b500caa523726e16",
            "max": 33384568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53eec775e6794566abad421e8d01b835",
            "value": 33384568
          }
        },
        "c8594db904bf4637a5858731cde9a664": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f532bdb6c747a8a6a27def3544d204": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9e8ec5a8c11472a99dbd5b679a3a572": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cddec2b417bc4f50b54b6f6960c02d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0b39f3de8b44f05810159bb8a616147": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d242a9860a274c2fbbed28e382dee554": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b61231cd91449ada00d7a11d0e7dfe5",
            "max": 4961251752,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72f0e99faddf4bc5859d0938febcaaa7",
            "value": 4961251752
          }
        },
        "d7f7fb4229ae454e811c3536434ada0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8725c4a0f3c4ee495545eb4f0f69944": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e52e21643c430a9041f3d2954f1357": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bec1c667580e4658bca78ce615106488",
            "max": 1156999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9df4d7143c8f451a9bb89de45d322ad0",
            "value": 1156999
          }
        },
        "db8740ca76e34a85b90c898ccd952ff8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db88ae59ba9e4f2b93b6bd6aee1a1e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd87846c577b4f2a9ff66c112b772b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0bd159a46c441648f1f6fa0bf1fef7d",
            "placeholder": "​",
            "style": "IPY_MODEL_a3b25709c62942b2bf56e6a726417e0e",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "de273b91d02c4802aef68f8e5bf07fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f9f54fb47ff94a3195bec8e0f54b4096",
              "IPY_MODEL_3174e818e510457a821b0563dcd70bce",
              "IPY_MODEL_e9dcf76d8c54434dabf32004a015493f"
            ],
            "layout": "IPY_MODEL_ef621668e93b4c169af80dd5548723e0"
          }
        },
        "dea07b194b894bd98082c9e2d7c57955": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "decd3cb8d67c4f75818f1d1a748a62fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfac8a771d85424da4bca9f327dbc656": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5604d12090646df905d25a536d7f2ad",
            "placeholder": "​",
            "style": "IPY_MODEL_279b09dcc33b4089aba54910b7ddd8a7",
            "value": " 855/855 [00:00&lt;00:00, 73.7kB/s]"
          }
        },
        "dfcab6dc6e7842fcaa03590a0b935d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3795615b2cab4189966699aba3f263d2",
            "placeholder": "​",
            "style": "IPY_MODEL_100776baf73e44faa0c72863b21dbe81",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "e31c5edada3b484b907a51077a05d288": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e53e461f869b45ba937a9d0878a74aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e852cd07728d48aabbb3b363704e44bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9dcf76d8c54434dabf32004a015493f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74957acb3c60499b9a1a366f6c9c9db6",
            "placeholder": "​",
            "style": "IPY_MODEL_baa1c14c050740daac3c66a8a870c9b9",
            "value": " 215/215 [00:00&lt;00:00, 22.2kB/s]"
          }
        },
        "ed8ac87f09b4470d814778580d7d0127": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ff6f2769e154ea6a51f4afdb752f2a2",
            "placeholder": "​",
            "style": "IPY_MODEL_e852cd07728d48aabbb3b363704e44bf",
            "value": " 2/2 [06:03&lt;00:00, 363.85s/it]"
          }
        },
        "eef9d3e14c804c86b668f9a4eaff141d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_215a19cc49054acd9afbfd2a215b6e6a",
            "max": 3639026128,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9e8ec5a8c11472a99dbd5b679a3a572",
            "value": 3639026128
          }
        },
        "ef621668e93b4c169af80dd5548723e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef81a31613bc417a80f426af81991d83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17a7ec2b4c344f791453234faf927a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08ea2b75483e4bac927555ec0278cd92",
              "IPY_MODEL_028b8c03ee9f4e219ffab1911fd8d5d9",
              "IPY_MODEL_0912a475313f4ae9893673866bb55920"
            ],
            "layout": "IPY_MODEL_119758192f464254817372255e315ca8"
          }
        },
        "f3df2b0087124db6984ec75b52fb03ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f521772d21415da8ba911b73707819": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c6eff3034d4e25aafef35ef8c187cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f82e7817016c41019b413091cbd76221": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96db30df7bb849d3a247116e3c68a5e3",
              "IPY_MODEL_c372c8f1e20a4503af7318a548c75eac",
              "IPY_MODEL_f87c0e7dd83f4e81bf459533c3f86c2b"
            ],
            "layout": "IPY_MODEL_06834803cd3344a699dfa52576391af6"
          }
        },
        "f855a6c300ca481a92347176780a720b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87c0e7dd83f4e81bf459533c3f86c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dea07b194b894bd98082c9e2d7c57955",
            "placeholder": "​",
            "style": "IPY_MODEL_be000a0749be4d029db464ef56e77e26",
            "value": " 33.4M/33.4M [00:00&lt;00:00, 49.6MB/s]"
          }
        },
        "f9f54fb47ff94a3195bec8e0f54b4096": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_decd3cb8d67c4f75818f1d1a748a62fe",
            "placeholder": "​",
            "style": "IPY_MODEL_cddec2b417bc4f50b54b6f6960c02d8f",
            "value": "generation_config.json: 100%"
          }
        },
        "fc1038d1ad554865996b57172569a661": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd900cd1975e4baead05350f82017293": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec0b860a5114a9b848a4c1c76db2b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff5b5ce5ed1149ff81de93277bc1b902": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
